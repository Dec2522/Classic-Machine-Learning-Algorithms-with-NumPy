High-level libraries make it relatively easy (he says) to implement ML algorithms. 
But with out a deep understanding of how they work you may struggle to match the 
problem with correct algorithm, interpret results, maximise their performance, 
troubleshoot issues, or be creative when and out the box method doesn't work.

In this repository I aim to prove to myself, through explanation, my understanding
of the algorithms. Those included are:

- Logistic Regression (Frequentist & Bayesian approach)
- Fixed Basis Expansions (Polynominal & Radial Basis Function)
- Clustering (KMeans & DBScan)
- Decision Trees and Random Forests
- Simple Feedforward Neural Network

Each algorithm is implemented with NumPy and then the results compared with those
of imported libraries (sklearn, PyTorch).

Data is either synthetically created or imported, so all that is needed is to run the 
files in a notebook environment (Google Colab, Jupyter).
